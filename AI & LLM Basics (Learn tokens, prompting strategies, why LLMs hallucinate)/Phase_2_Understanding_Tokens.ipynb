{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82f5201",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Phase 2: Understanding Tokens  \n",
    "*A practical and intuitive guide for beginners â€” with Gemini-focused context*\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ **1. What is a Token?**\n",
    "\n",
    "A **token** is the smallest chunk of text an LLM (like **Gemini**) processes.  \n",
    "Tokens can be:\n",
    "\n",
    "- Whole words  \n",
    "- Subwords  \n",
    "- Punctuation  \n",
    "- Special symbols  \n",
    "\n",
    "### ðŸ” **Examples**\n",
    "| Text | Tokens (example) |\n",
    "|------|------------------|\n",
    "| `Hello` | `Hello` |\n",
    "| `unhappiness` | `un`, `happiness` |\n",
    "| `I love LLMs!` | `I`, `love`, `LL`, `Ms`, `!` |\n",
    "\n",
    "Different models tokenize text differently.  \n",
    "But the idea is always the same:  \n",
    "âž¡ï¸ **LLMs understand text as sequences of tokens â€” not characters or words.**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  **Tokenization**\n",
    "Tokenization is the process of splitting text into tokens.\n",
    "\n",
    "Example:  \n",
    "> â€œunhappinessâ€ â†’ â€œunâ€, â€œhappinessâ€\n",
    "\n",
    "This allows the model to efficiently handle rare or complex words.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db46ef",
   "metadata": {},
   "source": [
    "## ðŸ§± **2. Token Limits & Context Windows**\n",
    "\n",
    "Every LLM has a maximum number of tokens it can handle at once.  \n",
    "This is known as a **context window**.\n",
    "\n",
    "### ðŸªŸ **Examples (Gemini models)**  \n",
    "| Model | Max Tokens |\n",
    "|-------|------------|\n",
    "| Gemini Flash 1.5 | ~1M tokens |\n",
    "| Gemini Pro 1.5 | ~2M tokens |\n",
    "| Gemini Ultra | ~2M tokens |\n",
    "\n",
    "> A *token limit* includes both:  \n",
    "> **Input tokens** + **Output tokens**\n",
    "\n",
    "---\n",
    "\n",
    "### â— Why Token Count Matters\n",
    "\n",
    "#### âœ” Cost  \n",
    "More tokens â†’ more processing â†’ higher API cost.\n",
    "\n",
    "#### âœ” Performance  \n",
    "Large prompts slow processing.\n",
    "\n",
    "#### âœ” Memory  \n",
    "The model must â€œrememberâ€ all tokens in a prompt while generating.\n",
    "\n",
    "---\n",
    "\n",
    "## Example  \n",
    "If your prompt is 20K tokens and you request 5K output tokens:\n",
    "\n",
    "Total = **25K tokens**\n",
    "\n",
    "This must be **â‰¤ model limit**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92588e5c",
   "metadata": {},
   "source": [
    "## ðŸ§ª **3. Hands-On: Counting Tokens**\n",
    "\n",
    "We will simulate token counting using a Python library.  \n",
    "Since we cannot use external APIs here, we will use a simple tokenizer approximation.\n",
    "\n",
    "> In real-world Gemini usage, you would use Google's tokenizer tools.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb507b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Gemini',\n",
       "  'models',\n",
       "  'can',\n",
       "  'handle',\n",
       "  'extremely',\n",
       "  'large',\n",
       "  'context',\n",
       "  'windows',\n",
       "  '.'],\n",
       " 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple token counter (approximation)\n",
    "# This splits text based on whitespace and punctuation.\n",
    "\n",
    "import re\n",
    "\n",
    "def simple_tokenize(text):\n",
    "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "    return tokens\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(simple_tokenize(text))\n",
    "\n",
    "sample = \"\"\"Gemini models can handle extremely large context windows.\"\"\"\n",
    "\n",
    "tokens = simple_tokenize(sample)\n",
    "tokens, len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72b9e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ’° **Estimating Token Cost**\n",
    "\n",
    "In Gemini, cost is often tied to:\n",
    "\n",
    "- **Input tokens processed**\n",
    "- **Output tokens generated**\n",
    "\n",
    "Below is a simple estimation example.\n",
    "\n",
    "> âš  This is *not* actual Gemini pricing â€” just a teaching demo.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84c82a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012000000000000002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fake cost estimation (teaching example)\n",
    "\n",
    "COST_PER_1K_INPUT = 0.0001\n",
    "COST_PER_1K_OUTPUT = 0.0002\n",
    "\n",
    "def estimate_cost(input_tokens, output_tokens):\n",
    "    return (input_tokens/1000 * COST_PER_1K_INPUT) +            (output_tokens/1000 * COST_PER_1K_OUTPUT)\n",
    "\n",
    "inp = 800   # example input tokens\n",
    "out = 200   # example output tokens\n",
    "\n",
    "estimated = estimate_cost(inp, out)\n",
    "estimated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29508eb7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Summary\n",
    "\n",
    "In this phase you learned:\n",
    "\n",
    "### âœ” What tokens are  \n",
    "### âœ” How text becomes tokens  \n",
    "### âœ” Why token limits matter  \n",
    "### âœ” How to count tokens  \n",
    "### âœ” How token usage affects cost  \n",
    "\n",
    "This foundation is essential before moving into **Prompting Fundamentals (Phase 3).**\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1cdc97",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
