{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c69b95b",
   "metadata": {},
   "source": [
    "# **Phase 1: Foundations of AI & LLMs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380aa76f",
   "metadata": {},
   "source": [
    "\n",
    "## **1. What is Artificial Intelligence (AI)?**\n",
    "\n",
    "### **Definition**\n",
    "AI refers to machines or software designed to perform tasks that normally require human intelligence.\n",
    "\n",
    "### **Types of AI**\n",
    "- **Narrow AI:** Designed for specific tasks (e.g., chatbots, recommendation engines).\n",
    "- **General AI (theoretical):** Human-level, capable of any intellectual task.\n",
    "\n",
    "### **Real-World Applications**\n",
    "- Virtual assistants  \n",
    "- Fraud detection  \n",
    "- Autonomous vehicles  \n",
    "- Medical diagnosis  \n",
    "- Smart recommendations (YouTube, Amazon)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0387f68",
   "metadata": {},
   "source": [
    "\n",
    "## **2. Introduction to Large Language Models (LLMs)**\n",
    "\n",
    "### **What Are LLMs?**\n",
    "LLMs are AI models trained on vast amounts of text to understand and generate human-like language.\n",
    "\n",
    "Examples:\n",
    "- **GPT** (OpenAI)  \n",
    "- **Llama** (Meta)  \n",
    "- **Claude** (Anthropic)  \n",
    "\n",
    "### **How LLMs Differ from Traditional Software**\n",
    "| Traditional Software | LLM-Based Systems |\n",
    "|----------------------|------------------|\n",
    "| Rule-based           | Pattern-based learning |\n",
    "| Predictable outputs  | Probabilistic outputs |\n",
    "| Needs explicit logic | Learns from data |\n",
    "\n",
    "### **Key Capabilities**\n",
    "- Text generation  \n",
    "- Summarization  \n",
    "- Code generation  \n",
    "- Reasoning (to some extent)  \n",
    "\n",
    "### **Limitations**\n",
    "- Can hallucinate  \n",
    "- May be biased  \n",
    "- Not always reliable for factual accuracy  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041bf798",
   "metadata": {},
   "source": [
    "\n",
    "## **3. How LLMs Work – High-Level Overview**\n",
    "\n",
    "### **Training on Massive Text Data**\n",
    "LLMs ingest billions of words and learn patterns, relationships, and structures.\n",
    "\n",
    "### **Predicting the Next Word/Token**\n",
    "The core mechanism is *probabilistic next-token prediction*.\n",
    "\n",
    "Example:\n",
    "```\n",
    "Input: \"The sky is\"\n",
    "Model predicts: \"blue\" with highest probability.\n",
    "```\n",
    "\n",
    "### **Concept of Parameters**\n",
    "- Parameters are internal configuration values learned during training.\n",
    "- More parameters generally → better reasoning and understanding.\n",
    "\n",
    "Example:\n",
    "- Small model: ~1B parameters  \n",
    "- Large model: ~70B+ parameters  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
