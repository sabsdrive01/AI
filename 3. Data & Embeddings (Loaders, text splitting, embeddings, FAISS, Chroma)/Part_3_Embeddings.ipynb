{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a7bec5",
   "metadata": {},
   "source": [
    "# Part 3 ‚Äî Embeddings\n",
    "### üß† How LLMs Understand Meaning with Numbers\n",
    "Embeddings convert text into high‚Äëdimensional numerical vectors that capture semantic meaning. They power RAG, semantic search, recommendation engines, and every modern LLM pipeline.\n",
    "\n",
    "This notebook teaches embeddings from scratch with simple explanations and a hands‚Äëon Gemini-powered demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a12e6",
   "metadata": {},
   "source": [
    "## üìò Learning Guide\n",
    "In this section, you will learn:\n",
    "- What embeddings are and why they matter\n",
    "- How semantic similarity works\n",
    "- How embeddings fit into the LLM/RAG pipeline\n",
    "- How to generate and compare embeddings using Gemini\n",
    "\n",
    "You will perform:\n",
    "- Vector generation\n",
    "- Cosine similarity comparison\n",
    "- Meaning‚Äëbased similarity tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6516b",
   "metadata": {},
   "source": [
    "## üîç 3.1 What Are Embeddings?\n",
    "Embeddings are vectors‚Äîlists of numbers‚Äîthat represent the meaning of text. Similar text produces similar vectors.\n",
    "\n",
    "Example vector:\n",
    "```\n",
    "[-0.12, 0.88, -0.55, ...]\n",
    "```\n",
    "Embeddings enable computers to **compare meanings mathematically**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26ffbb",
   "metadata": {},
   "source": [
    "## üîé Semantic Similarity & Cosine Distance\n",
    "Cosine similarity measures how close two meaning‚Äëvectors are:\n",
    "- `1.0` ‚Üí identical\n",
    "- `0.0` ‚Üí unrelated\n",
    "- `-1.0` ‚Üí opposite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b5d05",
   "metadata": {},
   "source": [
    "## üß© 3.2 Types of Embeddings\n",
    "- **Sentence embeddings** ‚Äî short text, clauses\n",
    "- **Document embeddings** ‚Äî full paragraphs/pages\n",
    "- **Providers:** Gemini, OpenAI, Cohere, Instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206363f1",
   "metadata": {},
   "source": [
    "## üß™ 3.3 Hands-On Demo ‚Äî Gemini Embeddings\n",
    "This demo generates embeddings for three text samples and compares them using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3051fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet numpy langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b841f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\selvam sabarish\\desktop\\sabs\\ai\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1 vs text2: 0.6878454685211182\n",
      "text1 vs text3: -0.01496809720993042\n",
      "text2 vs text3: -0.025115013122558594\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Model : all-MiniLM-L6-v2\n",
    "\n",
    "   - It is a lightweight sentence-transformer model created by Microsoft for generating high-quality text embeddings.\n",
    "\n",
    "    - It‚Äôs optimized for speed and efficiency, making it ideal for semantic search, chunking, and retrieval tasks on standard CPUs.\n",
    "\n",
    "    - Despite being small (22M parameters), it delivers strong performance and is widely used in RAG systems.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load model (downloads once, ~400MB)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sample texts\n",
    "text1 = \"Terminate the contract immediately.\"\n",
    "text2 = \"End the agreement right away.\"\n",
    "text3 = \"The weather is sunny today.\"\n",
    "\n",
    "# Generate embeddings\n",
    "v1, v2, v3 = model.encode([text1, text2, text3])\n",
    "\n",
    "# Cosine similarity\n",
    "def cosine_sim(a, b):\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
    "\n",
    "print(\"text1 vs text2:\", cosine_sim(v1, v2))\n",
    "print(\"text1 vs text3:\", cosine_sim(v1, v3))\n",
    "print(\"text2 vs text3:\", cosine_sim(v2, v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f4d96",
   "metadata": {},
   "outputs": [
    {
     "ename": "GoogleGenerativeAIError",
     "evalue": "Error embedding content: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0 [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerDayPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerDayPerUserPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerMinutePerProjectPerModel-FreeTier\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:306\u001b[39m, in \u001b[36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_embed_contents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mBatchEmbedContentsRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:1438\u001b[39m, in \u001b[36mGenerativeServiceClient.batch_embed_contents\u001b[39m\u001b[34m(self, request, model, requests, retry, timeout, metadata)\u001b[39m\n\u001b[32m   1437\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1438\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0 [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerDayPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerDayPerUserPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerMinutePerProjectPerModel-FreeTier\"\n}\n]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mGoogleGenerativeAIError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     23\u001b[39m texts = [\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTerminate the contract immediately.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEnd the agreement right away.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe weather is sunny today.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m ]\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Generate vectors\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m vectors = \u001b[43memb\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m v1, v2, v3 = vectors\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Cosine similarity\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:311\u001b[39m, in \u001b[36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[39m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    310\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError embedding content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m GoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    312\u001b[39m     embeddings.extend([\u001b[38;5;28mlist\u001b[39m(e.values) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m result.embeddings])\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[31mGoogleGenerativeAIError\u001b[39m: Error embedding content: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0\n* Quota exceeded for metric: generativelanguage.googleapis.com/embed_content_free_tier_requests, limit: 0 [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerDayPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerDayPerUserPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerMinutePerUserPerProjectPerModel-FreeTier\"\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/embed_content_free_tier_requests\"\n  quota_id: \"EmbedContentRequestsPerMinutePerProjectPerModel-FreeTier\"\n}\n]"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "from secrete_key import my_gemini_api_key\n",
    "API_KEY = my_gemini_api_key()\n",
    "\n",
    "\"\"\"\n",
    "Model : models/embedding-001\n",
    "\n",
    "It is Google‚Äôs proprietary embedding model used with the Gemini / Google Generative AI API.\n",
    "It converts text into dense numerical vectors that capture semantic meaning, enabling tasks like semantic search, clustering, and similarity comparisons.\n",
    "This model is hosted on Google‚Äôs servers and typically requires an API key and may be subject to usage quotas or billing.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Initialize\n",
    "emb = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=API_KEY\n",
    ")\n",
    "\n",
    "# Sample texts\n",
    "texts = [\n",
    "    \"Terminate the contract immediately.\",\n",
    "    \"End the agreement right away.\",\n",
    "    \"The weather is sunny today.\"\n",
    "]\n",
    "\n",
    "# Generate vectors\n",
    "vectors = emb.embed_documents(texts)\n",
    "v1, v2, v3 = vectors\n",
    "\n",
    "# Cosine similarity\n",
    "def cosine_sim(a, b):\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
    "\n",
    "print(\"text1 vs text2:\", cosine_sim(v1, v2))\n",
    "print(\"text1 vs text3:\", cosine_sim(v1, v3))\n",
    "print(\"text2 vs text3:\", cosine_sim(v2, v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6ee50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
