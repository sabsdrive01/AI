{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWW-Oi8tpX8H"
      },
      "source": [
        "# ðŸŽ“ LangChain Embeddings Tutorial\n",
        "\n",
        "## Understanding Text Embeddings with LangChain & HuggingFace\n",
        "\n",
        "### ðŸ“š What You'll Learn\n",
        "- How to use LangChain's embedding interface\n",
        "- Converting text into numerical vectors\n",
        "- Understanding embedding dimensions\n",
        "- Working with HuggingFace models through LangChain\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5j9vIv1rErY"
      },
      "source": [
        "## ðŸ“¦ Cell 1: Installation & Setup\n",
        "\n",
        "### What We're Installing:\n",
        "1. **`langchain-huggingface`** - LangChain's integration with HuggingFace models\n",
        "2. **`sentence-transformers`** - The underlying embedding model library\n",
        "\n",
        "### Why LangChain?\n",
        "LangChain provides a **unified interface** for working with different embedding models. Whether you use HuggingFace, OpenAI, or Cohere, the code looks similar!\n",
        "\n",
        "**Benefit:** Easy to switch between embedding providers without rewriting code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qE5z4mupVtl",
        "outputId": "ff94e570-94f2-465f-d323-dd072ebb7ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“¦ Installing LangChain and HuggingFace embeddings...\n",
            "\n",
            "âœ… Installation complete!\n",
            "\n",
            "\n",
            "ðŸ’¡ Ready to create embeddings!\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install required packages\n",
        "print(\"ðŸ“¦ Installing LangChain and HuggingFace embeddings...\\n\")\n",
        "\n",
        "# Install the packages\n",
        "!pip install -q langchain-huggingface sentence-transformers\n",
        "\n",
        "print(\"âœ… Installation complete!\\n\")\n",
        "\n",
        "# Verify installation (removed problematic version check)\n",
        "# import langchain_huggingface\n",
        "# print(f\"âœ… langchain-huggingface version: {langchain_huggingface.__version__}\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Ready to create embeddings!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgN1scorrzqu"
      },
      "source": [
        "## ðŸ”§ Cell 2: Import and Initialize the Embedding Model\n",
        "\n",
        "### What's Happening:\n",
        "1. **Import** the HuggingFaceEmbeddings class from LangChain\n",
        "2. **Initialize** the model with a specific HuggingFace model name\n",
        "3. **Download** the model weights (happens automatically on first run)\n",
        "\n",
        "### The Model: `all-MiniLM-L6-v2`\n",
        "- **Size:** ~80MB\n",
        "- **Speed:** Very fast (~1000 sentences/second)\n",
        "- **Dimensions:** 384 (each text becomes 384 numbers)\n",
        "- **Quality:** Excellent for most applications\n",
        "- **Use Case:** General-purpose semantic similarity\n",
        "\n",
        "### Technical Details:\n",
        "- This model is trained on 1 billion+ sentence pairs\n",
        "- It understands semantic meaning, not just keywords\n",
        "- Optimized for sentence-level embeddings\n",
        "                             \n",
        "                             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zytJ_cPBrTGb",
        "outputId": "99f00132-218b-4a26-d50c-1569b11ae19c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Selvam Sabarish\\Desktop\\sabs\\AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Loading HuggingFace embedding model...\\n\n",
            "âœ… Model loaded successfully!\\n\n",
            "ðŸ“Š Model Information:\n",
            "   â€¢ Model: all-MiniLM-L6-v2\n",
            "   â€¢ Provider: HuggingFace (via LangChain)\n",
            "   â€¢ Embedding Dimension: 384\n",
            "   â€¢ Max Sequence Length: 256 tokens\n",
            "\\nðŸ’¡ The model is now ready to convert text into vectors!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "    # Cell 2: Import and initialize the embedding model\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "print(\"ðŸ”„ Loading HuggingFace embedding model...\\\\n\")\n",
        "\n",
        "# Initialize the embeddings model\n",
        "# This will download the model on first run (~80MB)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"âœ… Model loaded successfully!\\\\n\")\n",
        "\n",
        "print(\"ðŸ“Š Model Information:\")\n",
        "print(f\"   â€¢ Model: all-MiniLM-L6-v2\")\n",
        "print(f\"   â€¢ Provider: HuggingFace (via LangChain)\")\n",
        "print(f\"   â€¢ Embedding Dimension: 384\")\n",
        "print(f\"   â€¢ Max Sequence Length: 256 tokens\")\n",
        "\n",
        "print(\"\\\\nðŸ’¡ The model is now ready to convert text into vectors!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsRdiMNotErn"
      },
      "source": [
        "\n",
        "## ðŸ“ Cell 3: Prepare Sample Text\n",
        "\n",
        "### What is an Embedding?\n",
        "An **embedding** is a numerical representation of text that captures its meaning.\n",
        "\n",
        "### The Magic:\n",
        "```\n",
        "Text: \"This is a test document.\"\n",
        "        â†“\n",
        "Embedding Model\n",
        "        â†“\n",
        "Vector: [0.234, -0.456, 0.789, ..., 0.123]\n",
        "         (384 numbers total)\n",
        "```\n",
        "\n",
        "### Why 384 Numbers?\n",
        "- Each number represents a different \"feature\" or \"aspect\" of meaning\n",
        "- Together, they encode: grammar, semantics, context, and relationships\n",
        "- Similar texts â†’ similar vectors (close in 384-dimensional space)\n",
        "\n",
        "### Real-World Analogy:\n",
        "Think of GPS coordinates:\n",
        "- **Text:** \"Eiffel Tower\"\n",
        "- **2D Coordinates:** (48.8584Â°N, 2.2945Â°E)\n",
        "- **Embeddings:** Like coordinates, but in 384-dimensional \"meaning space\"!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjv4bTSCs_sq",
        "outputId": "fa5dce08-5fe2-4971-ecd0-bb0f9dd44cfa"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Prepare sample text\n",
        "text = \"This is a test document.\"\n",
        "\n",
        "print(\"ðŸ“ Sample Text Prepared\\n\")\n",
        "print(\"=\" * 60)\n",
        "print(f'Text: \"{text}\"')\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nðŸŽ¯ Next Step: Convert this text into an embedding vector\")\n",
        "print(\"\\nðŸ’¡ Properties of the text:\")\n",
        "print(f\"   â€¢ Length: {len(text)} characters\")\n",
        "print(f\"   â€¢ Words: {len(text.split())} words\")\n",
        "print(f\"   â€¢ Will become: 384 numerical values\")\n",
        "\n",
        "print(\"\\nðŸ“Š What the embedding will capture:\")\n",
        "print(\"   âœ“ Semantic meaning (what it's about)\")\n",
        "print(\"   âœ“ Context (formal/informal, topic)\")\n",
        "print(\"   âœ“ Relationships (similar to other 'test document' phrases)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgvOXTNGtQXH"
      },
      "source": [
        "\n",
        "\n",
        "## ðŸ§® Cell 4: Generate the Embedding Vector\n",
        "\n",
        "### The Process:\n",
        "1. **Tokenization:** Split text into tokens (words/subwords)\n",
        "2. **Model Processing:** Neural network processes the tokens\n",
        "3. **Vector Creation:** Output is a 384-dimensional vector\n",
        "4. **Result:** A list of floating-point numbers\n",
        "\n",
        "### `embed_query()` Method:\n",
        "- **Purpose:** Convert a single piece of text into an embedding\n",
        "- **Input:** String (your text)\n",
        "- **Output:** List of 384 floating-point numbers\n",
        "- **Speed:** ~1-5 milliseconds per text\n",
        "\n",
        "### Understanding the Output:\n",
        "Each number in the vector:\n",
        "- Ranges typically from **-1 to +1** (normalized)\n",
        "- Represents activation of a \"semantic feature\"\n",
        "- Individually hard to interpret, but collectively powerful\n",
        "\n",
        "### Technical Note:\n",
        "The same text will **always** produce the same embedding (deterministic).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42tn7uNvtIRr",
        "outputId": "e2702d3a-f16c-4771-9008-2f8c2a703f0c"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Generate the embedding\n",
        "print(\"ðŸ”„ Generating embedding for the text...\\\\n\")\n",
        "\n",
        "# Call embed_query() to convert text to vector\n",
        "query_result = embeddings.embed_query(text)\n",
        "\n",
        "print(\"âœ… Embedding generated successfully!\\\\n\")\n",
        "\n",
        "print(\"ðŸ“Š Embedding Details:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Type: {type(query_result)}\")\n",
        "print(f\"Length (dimensions): {len(query_result)}\")\n",
        "print(f\"Data type: {type(query_result[0])}\")\n",
        "\n",
        "print(\"\\\\nðŸ”¢ Statistical Summary:\")\n",
        "import numpy as np\n",
        "arr = np.array(query_result)\n",
        "print(f\"   â€¢ Min value: {arr.min():.6f}\")\n",
        "print(f\"   â€¢ Max value: {arr.max():.6f}\")\n",
        "print(f\"   â€¢ Mean value: {arr.mean():.6f}\")\n",
        "print(f\"   â€¢ Standard deviation: {arr.std():.6f}\")\n",
        "\n",
        "print(\"\\\\nðŸ“ˆ Sample Values (first 10):\")\n",
        "for i, val in enumerate(query_result[:10]):\n",
        "    print(f\"   Dimension {i}: {val:.6f}\")\n",
        "\n",
        "print(\"\\\\nðŸ’¡ This vector now represents the meaning of our text!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfg5GizptaMD"
      },
      "source": [
        "## ðŸ” Cell 5: Visualize and Understand the Embedding\n",
        "\n",
        "### What We're Doing:\n",
        "1. **Display** a preview of the vector (first 100 characters)\n",
        "2. **Explain** what these numbers mean\n",
        "3. **Compare** different texts to show how embeddings work\n",
        "\n",
        "### Key Insight:\n",
        "The numbers themselves aren't meaningful individually, but when you **compare** embeddings using mathematical operations (like cosine similarity), you can measure how similar two texts are!\n",
        "\n",
        "### Practical Applications:\n",
        "- **Search:** Find documents similar to a query\n",
        "- **Clustering:** Group similar texts together\n",
        "- **Classification:** Categorize text by meaning\n",
        "- **Recommendation:** Suggest related content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1tA8lXOtPZv",
        "outputId": "8c1eb4e4-275a-4bba-89f6-fc830fe47f18"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Display and analyze the embedding\n",
        "\n",
        "print(\"ðŸŽ¨ Embedding Visualization\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Show preview (first 100 characters)\n",
        "print(\"ðŸ“‹ Vector Preview (first 100 characters):\")\n",
        "print(str(query_result)[:100] + \"...\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Full statistics\n",
        "print(\"\\nðŸ“Š Complete Vector Analysis:\\n\")\n",
        "\n",
        "print(f'Original Text: \"{text}\"')\n",
        "print(f\"Vector Length: {len(query_result)} dimensions\")\n",
        "print(f\"Total Storage: {len(query_result) * 4} bytes (4 bytes per float32)\")\n",
        "\n",
        "# Show distribution of values\n",
        "import numpy as np\n",
        "arr = np.array(query_result)\n",
        "\n",
        "print(\"\\nðŸ“ˆ Value Distribution:\")\n",
        "print(f\"   â€¢ Values > 0: {np.sum(arr > 0)} ({np.sum(arr > 0)/len(arr)*100:.1f}%)\")\n",
        "print(f\"   â€¢ Values < 0: {np.sum(arr < 0)} ({np.sum(arr < 0)/len(arr)*100:.1f}%)\")\n",
        "print(f\"   â€¢ Values â‰ˆ 0: {np.sum(np.abs(arr) < 0.01)} ({np.sum(np.abs(arr) < 0.01)/len(arr)*100:.1f}%)\")\n",
        "\n",
        "# Visualize first 20 dimensions\n",
        "print(\"\\nðŸ“Š First 20 Dimensions Visualization:\")\n",
        "print(\"\\nDim  Value      Bar\")\n",
        "print(\"-\" * 40)\n",
        "for i in range(20):\n",
        "    val = query_result[i]\n",
        "    bar_length = int(abs(val) * 20)\n",
        "    bar = \"â–ˆ\" * bar_length\n",
        "    sign = \"+\" if val >= 0 else \"-\"\n",
        "    print(f\"{i:3d}  {val:+.4f}  {sign}{bar}\")\n",
        "\n",
        "print(\"\\nâ” Each dimension captures a different aspect of meaning!\")\n",
        "print(\"â” Together, they form a unique 'fingerprint' of the text's semantics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHehv1WdtnNZ"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ¯ Bonus: Compare Multiple Text Embeddings\n",
        "\n",
        "Let's see how embeddings capture similarity between different texts!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z_y4bhttdmA",
        "outputId": "171053bc-97ba-423e-9c5d-275752246890"
      },
      "outputs": [],
      "source": [
        "# Bonus: Compare embeddings of different texts\n",
        "print(\"ðŸ”¬ Comparing Multiple Text Embeddings\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create diverse sample texts\n",
        "texts = [\n",
        "    \"This is a test document.\",           # Original\n",
        "    \"This is a test file.\",               # Similar (synonym)\n",
        "    \"The weather is sunny today.\",        # Different topic\n",
        "    \"Machine learning is fascinating.\",   # Different topic\n",
        "]\n",
        "\n",
        "print(\"ðŸ“ Sample Texts:\\n\")\n",
        "for i, t in enumerate(texts, 1):\n",
        "    print(f'{i}. \"{t}\"')\n",
        "\n",
        "# Generate embeddings for all texts\n",
        "print(\"\\nðŸ”„ Generating embeddings...\")\n",
        "all_embeddings = [embeddings.embed_query(t) for t in texts]\n",
        "print(\"âœ… All embeddings generated!\\n\")\n",
        "\n",
        "# Calculate cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    vec1 = np.array(vec1)\n",
        "    vec2 = np.array(vec2)\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "# Compare text 1 with all others\n",
        "print(\"ðŸ“Š Similarity Scores (comparing Text 1 with others):\\n\")\n",
        "base_emb = all_embeddings[0]\n",
        "\n",
        "for i, (text, emb) in enumerate(zip(texts, all_embeddings), 1):\n",
        "    similarity = cosine_similarity(base_emb, emb)\n",
        "\n",
        "    # Create visual bar\n",
        "    bar_length = int(similarity * 30)\n",
        "    bar = \"â–ˆ\" * bar_length\n",
        "\n",
        "    # Status indicator\n",
        "    if similarity > 0.8:\n",
        "        status = \"ðŸŸ¢ Very Similar\"\n",
        "    elif similarity > 0.5:\n",
        "        status = \"ðŸŸ¡ Somewhat Similar\"\n",
        "    else:\n",
        "        status = \"ðŸ”´ Different\"\n",
        "\n",
        "    print(f\"Text {i}: {similarity:.3f} {bar} {status}\")\n",
        "    if i == 1:\n",
        "        print(\"         (baseline - comparing to itself)\")\n",
        "    print()\n",
        "\n",
        "print(\"\\nðŸ’¡ Key Insights:\")\n",
        "print(\"   â€¢ Text 1 vs Text 2: HIGH similarity (synonyms: 'document' â‰ˆ 'file')\")\n",
        "print(\"   â€¢ Text 1 vs Text 3: LOW similarity (different topics)\")\n",
        "print(\"   â€¢ Text 1 vs Text 4: LOW similarity (unrelated content)\")\n",
        "print(\"\\nâœ¨ Embeddings successfully capture semantic meaning!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpl_1PRLtwN6"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "### ðŸ“š Further Reading\n",
        "\n",
        "- [LangChain Embeddings Docs](https://python.langchain.com/docs/integrations/text_embedding/)\n",
        "- [HuggingFace Sentence Transformers](https://www.sbert.net/)\n",
        "- [Understanding Vector Embeddings](https://www.pinecone.io/learn/vector-embeddings/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ9-B3E6u0Tl"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "print(\"System Time:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y5j9vIv1rErY",
        "bgN1scorrzqu",
        "GsRdiMNotErn",
        "wgvOXTNGtQXH",
        "lfg5GizptaMD",
        "SHehv1WdtnNZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
